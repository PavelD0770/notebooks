{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import dask.dataframe as dd\n",
    "import dask\n",
    "\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "\n",
    "path = \"dummy_dataset.parquet\"\n",
    "path_shuffled = \"dummy_dataset_shuffled.parquet\"\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Distributed-Dask Cluster and Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs/rzamora/miniconda3/envs/cudf_dev_sort/lib/python3.7/site-packages/distributed/dashboard/core.py:74: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:42410\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:40728/status' target='_blank'>http://127.0.0.1:40728/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>10</li>\n",
       "  <li><b>Cores: </b>80</li>\n",
       "  <li><b>Memory: </b>540.95 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:42410' processes=10 cores=80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Synthetic Dataset (Using Dask's `timeseries`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_create: 0.014232635498046875\n"
     ]
    }
   ],
   "source": [
    "# Start by creating a large dummy dataset\n",
    "# using Dask's internal `timeseries` example\n",
    "\n",
    "ts = time.time()\n",
    "ddf = dask.datasets.timeseries(\n",
    "    '1900', # Start year\n",
    "    '1925', # End year\n",
    "    #'2001', # End year\n",
    "    freq='1S', # Note: Use '1S' to create a \"huge\" df (3152995200 rows)\n",
    "    partition_freq='1Y',\n",
    "    seed=random_seed,\n",
    "    dtypes={\n",
    "        'value': float,\n",
    "        'name': str,\n",
    "        'id1000': int,\n",
    "    },  # data types\n",
    "    id1000_lam=1000,  # control number of items in id column\n",
    ")\n",
    "time_create = time.time() - ts\n",
    "print(\"time_create:\",time_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1900-12-31 00:00:00', freq='A-DEC')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.divisions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Distributed Parquet Dataset (File-per-Partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_clean: 0.08940005302429199\n",
      "time_gen_and_write: 268.7560443878174\n"
     ]
    }
   ],
   "source": [
    "# Use Dask's to_parquet to write data to a pyarrow-parquet \"dataset\"\n",
    "\n",
    "ts = time.time()\n",
    "if os.path.isdir(path):\n",
    "    shutil.rmtree(path)\n",
    "time_clean = time.time() - ts\n",
    "print(\"time_clean:\",time_clean)\n",
    "\n",
    "ts = time.time()\n",
    "ddf.to_parquet(path, write_index=True, engine=\"pyarrow\")\n",
    "time_gen_and_write = time.time() - ts\n",
    "print(\"time_gen_and_write:\",time_gen_and_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Read Dataset and Write back Shuffled/Processed Data (CPU Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_read_meta 1.3047316074371338\n"
     ]
    }
   ],
   "source": [
    "# Read back the parquet dataset on CPU `read_parquet`\n",
    "\n",
    "ts = time.time()\n",
    "ddf_read = dd.read_parquet(path, index=\"timestamp\", gather_statistics=True, engine=\"pyarrow\")\n",
    "time_read_meta = time.time() - ts\n",
    "print(\"time_read_meta\", time_read_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1900-12-31 00:00:00')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_read.divisions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_read.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add a new column to shuffle the dataset\n",
    "\n",
    "def _assign_rand(df):\n",
    "    return df.assign(sort_ind=np.random.permutation(len(df)))\n",
    "ddf_read_new = ddf_read.map_partitions(_assign_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_set_index_sort_ind 63.44454836845398\n"
     ]
    }
   ],
   "source": [
    "# Set index to column `sort_ind` to shuffle the dataset\n",
    "\n",
    "ts = time.time()\n",
    "ddf_read_shuffled = ddf_read_new.set_index('sort_ind')\n",
    "time_set_index_sort_ind = time.time() - ts\n",
    "print(\"time_set_index_sort_ind\", time_set_index_sort_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_read_shuffled.divisions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_read_shuffled.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_shuffle: 300.01719093322754\n"
     ]
    }
   ],
   "source": [
    "# Show time for shuffle (Shouldn't actually do this step in practice)\n",
    "\n",
    "ts = time.time()\n",
    "ddf_read_shuffled.compute()\n",
    "time_shuffle = time.time() - ts\n",
    "print(\"time_shuffle:\",time_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_clean: 0.07477879524230957\n",
      "time_gen_and_write: 295.2648060321808\n"
     ]
    }
   ],
   "source": [
    "# Write out \"shuffled\" dataset\n",
    "# Total time is shuffle + write\n",
    "\n",
    "ts = time.time()\n",
    "if os.path.isdir(path_shuffled):\n",
    "    shutil.rmtree(path_shuffled)\n",
    "time_clean = time.time() - ts\n",
    "print(\"time_clean:\",time_clean)\n",
    "\n",
    "ts = time.time()\n",
    "ddf_read_shuffled.to_parquet(path_shuffled, write_index=False, engine=\"pyarrow\")\n",
    "time_gen_and_write = time.time() - ts\n",
    "print(\"time_gen_and_write:\",time_gen_and_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_read_meta 1.7234370708465576\n"
     ]
    }
   ],
   "source": [
    "# Read back the \"shuffled\" parquet dataset on CPU\n",
    "ts = time.time()\n",
    "ddf_read_shuffled_2 = dd.read_parquet(path_shuffled, index=False, gather_statistics=True ,engine=\"pyarrow\")\n",
    "time_read_meta = time.time() - ts\n",
    "print(\"time_read_meta\", time_read_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1000</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>0.823693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1025</td>\n",
       "      <td>George</td>\n",
       "      <td>-0.172319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>982</td>\n",
       "      <td>Frank</td>\n",
       "      <td>-0.017929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>994</td>\n",
       "      <td>Ursula</td>\n",
       "      <td>-0.817381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>992</td>\n",
       "      <td>Michael</td>\n",
       "      <td>-0.356457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id1000     name     value\n",
       "0    1021   Xavier  0.823693\n",
       "1    1025   George -0.172319\n",
       "2     982    Frank -0.017929\n",
       "3     994   Ursula -0.817381\n",
       "4     992  Michael -0.356457"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_read_shuffled_2.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
