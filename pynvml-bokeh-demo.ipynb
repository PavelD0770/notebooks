{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing GPU Resource Utilization with PyNVML and Bokeh\n",
    "\n",
    "- **Author:** Rick Zamora\n",
    "- **Date:** 5/15/2019\n",
    "\n",
    "### Introduction\n",
    "\n",
    "\n",
    "\n",
    "### Base Envirnonment Setup\n",
    "\n",
    "In order to visualize GPU utilization for this demo, we start by createing a base conda environment with [RAPIDS](https://rapids.ai/) and [Jupyter](https://jupyter.org/) packages:\n",
    "```\n",
    "conda create --name bokeh-pynvml \\\n",
    "    -c defaults -c nvidia -c rapidsai \\\n",
    "    -c pytorch -c numba -c conda-forge \\\n",
    "    cudf=0.7 cuml=0.7 python=3.7 cudatoolkit=9.2 \\\n",
    "    nodejs jupyterlab dask dask-cudf dask-cuda bokeh -y\n",
    "conda activate bokeh-pynvml\n",
    "```\n",
    "\n",
    "Note that I am personally using a DGX machine with eight V100 NVIDIA GPUs for the development of this demo (`Ubuntu 16.04.5 LTS (GNU/Linux 4.4.0-135-generic x86_64`).\n",
    "\n",
    "Before or after activating our base conda environment, we should also choose a specific root-directory location for this demo:\n",
    "```\n",
    "export demo_home='/home/nfs/rzamora/workspace/pynvml-bokeh-demo'\n",
    "mkdir $demo_home; cd $demo_home\n",
    "```\n",
    "\n",
    "### Python Bindings for the NVIDIA Management Library (PyNVML)\n",
    "\n",
    "PyNVML is a python wrapper for the [NVIDIA Management Library (NVML)](https://developer.nvidia.com/nvidia-management-library-nvml), which is a C-based API for monitoring and managing various states of NVIDIA GPU devices. NVML is directly used by the better-known [NVIDIA System Management Interface](https://developer.nvidia.com/nvidia-system-management-interface) (`nvidia-smi`). According to the NVIDA developer site, NVML provides access to the following query-able states (in additional to modifiable states not discussed here):\n",
    "\n",
    "- **ECC error counts**: Both correctable single bit and detectable double bit errors are reported. Error counts are provided for both the current boot cycle and for the lifetime of the GPU.\n",
    "- **GPU utilization**: Current utilization rates are reported for both the compute resources of the GPU and the memory interface.\n",
    "- **Active compute process**: The list of active processes running on the GPU is reported, along with the corresponding process name/id and allocated GPU memory.\n",
    "- **Clocks and PState**: Max and current clock rates are reported for several important clock domains, as well as the current GPU performance state.\n",
    "- **Temperature and fan speed**: The current core GPU temperature is reported, along with fan speeds for non-passive products.\n",
    "- **Power management**: For supported products, the current board power draw and power limits are reported.\n",
    "- **Identification**: Various dynamic and static information is reported, including board serial numbers, PCI device ids, VBIOS/Inforom version numbers and product names.\n",
    "\n",
    "Although several different python wrappers for NVML currently exist, I will be using the [PyNVML](https://github.com/gpuopenanalytics/pynvml) package hosted by GoAi on GitHub. This version of PyNVML uses `ctypes` to wrap most of the NVML C API.  For this demo, we will focus on a small subset of the API needed to query real-time GPU-resource utilization:\n",
    "\n",
    "- `nvmlInit()`: Initialize an NVML profiling session\n",
    "- `nvmlShutdown()`: Finalize an NVML profiling session\n",
    "- `nvmlDeviceGetCount()`: Get the number of available NVIDA GPU devices\n",
    "- `nvmlDeviceGetHandleByIndex()`: Get a handle for a device (given an integer index)\n",
    "- `nvmlDeviceGetMemoryInfo()`: Get a memory-info object (given a device handle)\n",
    "- `nvmlDeviceGetUtilizationRates()`: Get a utlization-rate object (given a device handle)\n",
    "- `nvmlDeviceGetPcieThroughput()`: Get a PCIe-trhoughput object (given a device handle)\n",
    "\n",
    "For example, to query the current GPU-utilization rate on every available device, the code would look something like this:\n",
    "\n",
    "```\n",
    "In [1]: from pynvml import *\n",
    "In [2]: nvmlInit()\n",
    "In [3]: ngpus = nvmlDeviceGetCount()\n",
    "In [4]: for i in range(ngpus):\n",
    "   ...:     handle = nvmlDeviceGetHandleByIndex(i)\n",
    "   ...:     gpu_util = nvmlDeviceGetUtilizationRates(handle).gpu\n",
    "   ...:     print('GPU %d Utilization = %d%%' % (i, gpu_util))\n",
    "   ...:\n",
    "GPU 0 Utilization = 43%\n",
    "GPU 1 Utilization = 0%\n",
    "GPU 2 Utilization = 15%\n",
    "GPU 3 Utilization = 0%\n",
    "GPU 4 Utilization = 36%\n",
    "GPU 5 Utilization = 0%\n",
    "GPU 6 Utilization = 0%\n",
    "GPU 7 Utilization = 11%\n",
    "```\n",
    "\n",
    "Of courese, if there is nothing currently running on any of the GPUs, all devices will show 0% utilization. In this demo, we will use simple python code (like in the above example) to query GPU metrics in real time.  To intall [PyNVML](https://github.com/gpuopenanalytics/pynvml) from source:\n",
    "```\n",
    "git clone https://github.com/gpuopenanalytics/pynvml.git\n",
    "cd pynvml\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Note that this version of PyNVML is also hosted on [PyPI](https://pypi.org/project/pynvml/) and [Conda Forge](https://anaconda.org/conda-forge/pynvml), so you can alternitively use `pip install pynvml` or `conda install -c conda-forge pynvml` without cloning the repository.\n",
    "\n",
    "\n",
    "![alt text](pynvml-bokeh-files/pypi-ss.png)\n",
    "**PyPI page for PyNVML packag**\n",
    "\n",
    "\n",
    "### A PyNVML Bokeh-Server Example\n",
    "\n",
    "Although it is pretty cool that we can use python to query the current state of our NVIDIA GPUs, it would be a lot more useful to sumarize the most-important metrics within a single visualization.  In order for the visualization to *paint* a complete/useful picture for GPU users, the NVML data will clearly need to update in real time. \n",
    "\n",
    "The good news is that the `server` module within the [Bokeh](https://bokeh.pydata.org/en/latest/) python library provides the perfect solution for this task!  In fact, the process of building programmatic bokeh servers is already nicely outlined in a [great blog post by Matt Rocklin](http://matthewrocklin.com/blog/work/2017/06/28/simple-bokeh-server) (thanks Matt!). \n",
    "\n",
    "For this demo, I will be using a fork of the [`jupyterlab-bokeh-server`](https://github.com/ian-r-rose/jupyterlab-bokeh-server), developed by [Ian Rose](https://github.com/ian-r-rose) and [Matt Rocklin](https://github.com/mrocklin).  In my person fork, I started with the `system-resources` branch of the upstream repository.  This branch was a great reference, because it includes the necessary code for visualising CPU resource utilization (which is pretty similar to the code needed to vizualize GPU utilization).\n",
    "\n",
    "#### Downloading the Bokeh-Server Code\n",
    "\n",
    "To get the code I added for NVML-metric visualization, clone the `pynvml` branch of [`rjzamora/jupyterlab-bokeh-server`](https://github.com/rjzamora/jupyterlab-bokeh-server):\n",
    "\n",
    "```\n",
    "cd $demo_home\n",
    "git clone https://github.com/rjzamora/jupyterlab-bokeh-server.git -b pynvml\n",
    "```\n",
    "\n",
    "#### Running the PyNVML Bokeh Server\n",
    "\n",
    "Despite the existance `jupyterlab` within the name of the repository used for this demo, I have yet to integrate the server as a jupyterlab extension.  Instead, we can currently use the code by running the `jupyterlab_bokeh_server/server.py` script directly. For example:\n",
    "\n",
    "```\n",
    "python $demo_home/jupyterlab-bokeh-server/jupyterlab_bokeh_server/server.py 5000 > server.out 2>&1 &\n",
    "```\n",
    "\n",
    "After the bokeh server is launched, you can navigate to `http://<IP>:5000` in your web browser. If everything worked correctly, you will see the following menue page:\n",
    "\n",
    "![alt text](pynvml-bokeh-files/bokeh-app-ss.png)\n",
    "\n",
    "##### GPU-Utilization Bar Plot\n",
    "\n",
    "If you click on the **GPU-Utilization** link listed in the main menue, you will see a bar-chart visualization of the current GPU compute utilization (y-axis scale being 1-100%).  When running an application on the GPUs, the bar levels tend to jump around alot.  For the dask benchmark (discussed below), I see the following output for a single snapshot in time (with other snapshots showing more and less utilization):\n",
    "\n",
    "![alt text](pynvml-bokeh-files/gpu-utilization-ss.png)\n",
    "\n",
    "##### GPU-Resources Stacked Line Plot\n",
    "\n",
    "If you click on the **GPU-Resources** link listed in the main menue, you will see a comprehensive visualization with four stacked line plots. \n",
    "\n",
    "- **GPU Utilization (per Device) [%]**: Plot of the GPU-**compute** utilization for each device. Each GPU is plotted with a different color, and the units are in percent.\n",
    "- **Memory Utilization (per Device)**: Plot of the GPU-**memory** utilization for each device. Each GPU is plotted with a different color, and the units are in GiB.\n",
    "- **Total Utilization [%]**: Plot of the **total** GPU **memory** and **compute** utilization. Units are in percent.\n",
    "- **Total PCI Throughput [MB/s]**: Plot of the **total** PCIe **TX** and **RX** data throughput. Units are in MB/s.\n",
    "\n",
    "When running the dask benchmark (discussed below), I see the following output for a ~10s snapshot in time:\n",
    "\n",
    "![alt text](pynvml-bokeh-files/gpu-resources-ss.png)\n",
    "\n",
    "#### Bokeh-Server Code Details\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dask GPU Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
